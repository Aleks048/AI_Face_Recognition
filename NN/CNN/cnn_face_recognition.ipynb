{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [
     56,
     89,
     235,
     248
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images are loaded!\n",
      "3150 training set\n",
      "1350 test set\n",
      "load model\n",
      "1350/1350 [==============================] - 11s 8ms/step\n",
      "loss:  0.02758220835485392 accuracy:  99.18518662452698 %\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import cv2\n",
    "from PIL import ImageGrab\n",
    "from keras import backend as K\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Activation, Flatten\n",
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from ipynb.fs.full.config import getItem_string\n",
    "from ipynb.fs.full.config import getItem_int\n",
    "from ipynb.fs.full.Util import dictToTxt,TxtToDict\n",
    "from ipynb.fs.full.preprocessing_images import generate_train_set,generate_test_set,loadImage\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "#load dataset for training\n",
    "#return all images in the dataset & corresponding name labels\n",
    "def load_all_dataset(path):\n",
    "    images=[]\n",
    "    labels=[] \n",
    "    dictionary={}\n",
    "    images,labels = loadImage(path)  \n",
    "    #convert images to 4d array  (number_of_image, size_of_image,size_of_image,3)   3 means RGB\n",
    "    images = np.array(images)\n",
    "#     print(images.shape) \n",
    "    #label all images with corresponding names(numbers) \n",
    "    res_labels=[]\n",
    "    before_name=\"\"\n",
    "    number=0\n",
    "    for label in range(len(labels)):\n",
    "        #if it is the first image\n",
    "        if label==0:\n",
    "            res_labels.append(number)\n",
    "            before_name=labels[label]\n",
    "            dictionary.update({str(number):labels[label]})\n",
    "        else:\n",
    "            #if last name is same as current one, append same number to the label array\n",
    "            if before_name==labels[label]:\n",
    "                res_labels.append(number)\n",
    "            else:#last name is different from current one, meaning an image from other person)\n",
    "                number+=1\n",
    "                res_labels.append(number) \n",
    "                before_name=labels[label] \n",
    "                dictionary.update({str(number):labels[label]})\n",
    "#             print(images)\n",
    "#             print(res_labels)\n",
    "    \n",
    "    dictToTxt(dictionary,\"names.txt\") \n",
    "    return images, res_labels\n",
    "    \n",
    "\n",
    "def load_training_dataset(path):\n",
    "    images=[]\n",
    "    labels=[] \n",
    "    dictionary={}\n",
    "    images,labels = generate_train_set()\n",
    "    #convert images to 4d array  (number_of_image, size_of_image,size_of_image,3)   3 means RGB\n",
    "    images = np.array(images)\n",
    "#     print(images.shape) \n",
    "    #label all images with corresponding names(numbers) \n",
    "    res_labels=[]\n",
    "    before_name=\"\"\n",
    "    number=0\n",
    "    for label in range(len(labels)):\n",
    "        #if it is the first image\n",
    "        if label==0:\n",
    "            res_labels.append(number)\n",
    "            before_name=labels[label]\n",
    "            dictionary.update({str(number):labels[label]})\n",
    "        else:\n",
    "            #if last name is same as current one, append same number to the label array\n",
    "            if before_name==labels[label]:\n",
    "                res_labels.append(number)\n",
    "            else:#last name is different from current one, meaning an image from other person)\n",
    "                number+=1\n",
    "                res_labels.append(number) \n",
    "                before_name=labels[label] \n",
    "                dictionary.update({str(number):labels[label]})\n",
    "#             print(images)\n",
    "#             print(res_labels)\n",
    "    \n",
    "    dictToTxt(dictionary,\"train_names.txt\") \n",
    "    return images, res_labels    \n",
    "\n",
    "def load_test_dataset(path):\n",
    "    images=[]\n",
    "    labels=[] \n",
    "    dictionary={}\n",
    "    images,labels = generate_test_set()\n",
    "    print(len(images))\n",
    "    #convert images to 4d array  (number_of_image, size_of_image,size_of_image,3)   3 means RGB\n",
    "    images = np.array(images)\n",
    "#     print(images.shape) \n",
    "    #label all images with corresponding names(numbers) \n",
    "    res_labels=[]\n",
    "    before_name=\"\"\n",
    "    number=0\n",
    "    for label in range(len(labels)):\n",
    "        #if it is the first image\n",
    "        if label==0:\n",
    "            res_labels.append(number)\n",
    "            before_name=labels[label]\n",
    "            dictionary.update({str(number):labels[label]})\n",
    "        else:\n",
    "            #if last name is same as current one, append same number to the label array\n",
    "            if before_name==labels[label]:\n",
    "                res_labels.append(number)\n",
    "            else:#last name is different from current one, meaning an image from other person)\n",
    "                number+=1\n",
    "                res_labels.append(number) \n",
    "                before_name=labels[label] \n",
    "                dictionary.update({str(number):labels[label]})\n",
    "#             print(images)\n",
    "#             print(res_labels)\n",
    "    \n",
    "    dictToTxt(dictionary,\"test_names.txt\") \n",
    "    return images, res_labels   \n",
    "\n",
    "#load training set, test set\n",
    "def load(dataset):\n",
    "    size = getItem_int(\"dataset\",\"image_size\")\n",
    "    numberOfClass = getItem_int(\"dataset\",\"number_of_class\")\n",
    "    #RGB has 3 channels\n",
    "    channel = 3\n",
    "\n",
    "    images,labels = load_all_dataset(getItem_string(\"dataset\",\"test_dataset_path\"))\n",
    "    train_images, test_images, train_labels, test_labels = train_test_split(images, labels, test_size = 0.3, random_state = random.randint(0, 100))                 \n",
    "                                        #number of images,     size,size,   channel)\n",
    "    train_images = train_images.reshape(train_images.shape[0], size, size, channel)\n",
    "    test_images = test_images.reshape(test_images.shape[0], size, size, channel)            \n",
    "\n",
    "    print(train_images.shape[0], 'training set')\n",
    "    print(test_images.shape[0], 'test set')                            \n",
    "    train_labels = np_utils.to_categorical(train_labels, numberOfClass)                        \n",
    "    test_labels = np_utils.to_categorical(test_labels, numberOfClass)   \n",
    "    \n",
    "    #normalize\n",
    "    train_images = train_images.astype('float32')    \n",
    "    test_images  = test_images.astype('float32')\n",
    "    \n",
    "    train_images/=255\n",
    "    test_images/=255\n",
    "    \n",
    "\n",
    "    \n",
    "    return train_images, test_images, train_labels, test_labels\n",
    "\n",
    "                    \n",
    "        \n",
    "def build_model():\n",
    "    IMAGE_SIZE=getItem_int(\"dataset\",\"image_size\")\n",
    "    numberOfClass =  getItem_int(\"dataset\",\"number_of_class\")\n",
    "    model = Sequential([\n",
    "        Conv2D(64, (3, 3),activation='relu',padding='same',input_shape=(IMAGE_SIZE,IMAGE_SIZE,3)),\n",
    "        Conv2D(64, (3, 3),activation='relu'),\n",
    "        MaxPooling2D(2, 2),\n",
    "        Dropout(0.25),       \n",
    "        Conv2D(64, (3, 3),activation='relu',padding='same'),      \n",
    "        Conv2D(64, (3, 3),activation='relu',padding='same'),\n",
    "        MaxPooling2D(2, 2),\n",
    "        Dropout(0.25),        \n",
    "        Flatten(),\n",
    "        Dense(512,activation='relu'),\n",
    "        Dense(numberOfClass,activation='softmax')\n",
    "    ])\n",
    "    #print network\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "\n",
    "    #train the model\n",
    "def train(model, epochs,train_images, train_labels):        \n",
    "    sgd = SGD() \n",
    "    model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])  \n",
    "    #add variations\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=True,\n",
    "        featurewise_std_normalization=True,\n",
    "        zca_whitening = False,\n",
    "        rotation_range=270,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2)\n",
    "    datagen.fit(train_images) \n",
    "   \n",
    "    model.fit_generator(datagen.flow(train_images, train_labels,batch_size=20),\n",
    "                             steps_per_epoch=len(train_images) / 20,\n",
    "                             epochs = epochs) \n",
    "    print(\"training done\")\n",
    "    return model\n",
    "    \n",
    "   \n",
    "def saveModel(model, path):  \n",
    "    print(\"save model\")\n",
    "    model.save(path)\n",
    "    print(\"saved successfully\")\n",
    "\n",
    "def loadModel(path):  \n",
    "    print(\"load model\")\n",
    "    return load_model(path)\n",
    "    \n",
    " \n",
    "def evaluate(model, test_images, test_labels):\n",
    "    #open progress bar\n",
    "    score = model.evaluate(test_images, test_labels, verbose = 1)\n",
    "#          print(\"%s: %.2f%%\" % (model.metrics_names[1], score[1] * 100))\n",
    "    print(\"loss: \",score[0], \"accuracy: \",score[1] * 100,\"%\")\n",
    "\n",
    "    #predict face\n",
    "def face_predict(model,image):  \n",
    "    IMAGE_SIZE=getItem_int(\"dataset\",\"image_size\")\n",
    "    image = cv2.resize(image,(IMAGE_SIZE,IMAGE_SIZE))     \n",
    "    image = image.reshape((1, IMAGE_SIZE, IMAGE_SIZE, 3))                    \n",
    "\n",
    "    #normalize\n",
    "    image= image.astype('float32')\n",
    "    image/=255\n",
    "    #between 0-1\n",
    "    prob = model.predict_proba(image)#[[1,2,3,4]]\n",
    "    print('result-------', prob)\n",
    "\n",
    "    prob = prob[0].tolist()\n",
    "    maxValue = max(prob)\n",
    "    print(maxValue)\n",
    "    maxIndex = prob.index(maxValue) \n",
    "    #return the result\n",
    "    if(maxValue>0.9):\n",
    "        return maxIndex\n",
    "    else:\n",
    "        return -1\n",
    "    \n",
    "def resizeWindow(image, width=None, height=None, inter=cv2.INTER_AREA):\n",
    "    dim = None\n",
    "    (h, w) = image.shape[:2]\n",
    "    if width is None and height is None:\n",
    "        return image\n",
    "    if width is None:\n",
    "        r = height / float(h)\n",
    "        dim = (int(w * r), height)\n",
    "    else:\n",
    "        r = width / float(w)\n",
    "        dim = (width, int(h * r))\n",
    "    return cv2.resize(image, dim, interpolation=inter) \n",
    "\n",
    "#image(require a imgpath) or video or camera \n",
    "def test(source,path):\n",
    "    #load the model\n",
    "    model = loadModel(getItem_string(\"dataset\",\"model_path\"))    \n",
    "    #get names\n",
    "    dictionary = TxtToDict(\"names.txt\")\n",
    "    if(source==\"camera\"):\n",
    "        cap = cv2.VideoCapture(0)\n",
    "        cv2.namedWindow('Camera')\n",
    "        while True:\n",
    "            #read a frame\n",
    "            ret, frame = cap.read()      \n",
    "            if ret is True: \n",
    "                #convert into greyscale\n",
    "                grayscale_image = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            #create a cascade classifier\n",
    "            face_cascade = cv2.CascadeClassifier(getItem_string(\"opencv\",\"cascadeclassifier\")  )                \n",
    "\n",
    "            #detect faces \n",
    "            faceRects = face_cascade.detectMultiScale(grayscale_image,scaleFactor = 1.2,minNeighbors = 3)  \n",
    "            personId=-1\n",
    "            #if any face is detected\n",
    "            if len(faceRects) > 0:                 \n",
    "                for (x,y,w,h) in faceRects: \n",
    "                    #draw rectangles contained faces\n",
    "                    frame = cv2.rectangle(frame,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "                    ##crop images, make the area bigger to improve the rate\n",
    "                    image = frame[y-10: y+h+10, x-10: x+w+10]\n",
    "                    personId = face_predict(model,image)   \n",
    "\n",
    "               #no one detected                       \n",
    "                if(personId== -1):        \n",
    "                    cv2.putText(frame,                   #window\n",
    "                                \"unknown\",               #name\n",
    "                                (x,y),                   #coordinate\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX,#font\n",
    "                                1,                       #font size\n",
    "                                255,                     #color\n",
    "                                2)                       #stroke weight\n",
    "                else:\n",
    "                    cv2.putText(frame,                   #window\n",
    "                                dictionary[str(personId)],#name\n",
    "                                (x,y),                   #coordinate\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX,#font\n",
    "                                1,                       #font size\n",
    "                                255,                     #color\n",
    "                                2)                       #stroke weight\n",
    "            else:\n",
    "                continue                   \n",
    "            cv2.imshow(\"Camera\", frame)\n",
    "            k = cv2.waitKey(10)  \n",
    "            #press q to exit\n",
    "            if k & 0xFF == ord('q'):\n",
    "                break\n",
    "        cap.release()\n",
    "                \n",
    "    elif(source=='video'):                \n",
    "        while True:\n",
    "            #get a specfic area on the screen\n",
    "            screenshot =  ImageGrab.grab(bbox=(40,290,890,770))\n",
    "            #reshape the image\n",
    "            screenshot_numpy =   np.array(screenshot.getdata(),dtype='uint8')\\\n",
    "            .reshape((screenshot.size[1],screenshot.size[0],3))\n",
    "            #resize window\n",
    "            shrinkedWindow = resizeWindow(screenshot_numpy,650) \n",
    "            #convert into greyscale\n",
    "            grayscale_image = cv2.cvtColor(shrinkedWindow, cv2.COLOR_BGR2GRAY)\n",
    "            #create a cascade classifier\n",
    "            face_cascade = cv2.CascadeClassifier(getItem_string(\"opencv\",\"cascadeclassifier\"))                \n",
    "            #detect faces\n",
    "            faceRects = face_cascade.detectMultiScale(grayscale_image,scaleFactor = 1.2,minNeighbors = 3)   \n",
    "            #if any face is detected\n",
    "            if len(faceRects) > 0:                 \n",
    "                for (x,y,w,h) in faceRects: \n",
    "                    #draw rectangles contained faces\n",
    "                    shrinkedWindow = cv2.rectangle(shrinkedWindow,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "                    ##crop images, make the area bigger to improve the success rate\n",
    "                    image = shrinkedWindow[y-10: y+h+10, x-10: x+w+10]\n",
    "                    #predict\n",
    "                    personId = face_predict(model,image)   \n",
    "\n",
    "                #no one detected                       \n",
    "                if(personId== -1):        \n",
    "                    cv2.putText(shrinkedWindow,          #window\n",
    "                                \"unknown\",               #name\n",
    "                                (x,y),                   #coordinate\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX,#font\n",
    "                                1,                       #font size\n",
    "                                255,                     #color\n",
    "                                2)                       #stroke weight\n",
    "                else:\n",
    "                    cv2.putText(shrinkedWindow,          #window\n",
    "                                dictionary[str(personId)],#name\n",
    "                                (x,y),                   #coordinate\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX,#font\n",
    "                                1,                       #font size\n",
    "                                255,                     #color\n",
    "                                2)                       #stroke weight\n",
    "\n",
    "            else:\n",
    "                continue        \n",
    "\n",
    "            cv2.imshow('video',cv2.cvtColor(shrinkedWindow, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "            k = cv2.waitKey(20)\n",
    "            #press q to exit\n",
    "            if k & 0xFF == ord('q'):\n",
    "                break\n",
    "    elif(source=='image'):\n",
    "        while True:       \n",
    "            img = cv2.imread(path)\n",
    "            img = cv2.resize(img,(400,400))\n",
    "            #convert into greyscale\n",
    "            grayscale_image = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            #create a cascade classifier\n",
    "            face_cascade = cv2.CascadeClassifier(getItem_string(\"opencv\",\"cascadeclassifier\"))                \n",
    "            #detect faces\n",
    "            faceRects = face_cascade.detectMultiScale(grayscale_image,scaleFactor = 1.2,minNeighbors = 3)   \n",
    "            #if any face is detected\n",
    "            if len(faceRects) > 0:                 \n",
    "                for (x,y,w,h) in faceRects: \n",
    "                    #draw rectangles contained faces\n",
    "                    img = cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "                    ##crop images, make the area bigger to improve the success rate\n",
    "                    image = img[y-10: y+h+10, x-10: x+w+10]\n",
    "                    #predict\n",
    "                    personId = face_predict(model,image)   \n",
    "\n",
    "                #no one detected                       \n",
    "                if(personId== -1):        \n",
    "                    cv2.putText(img,          #window\n",
    "                                \"unknown\",               #name\n",
    "                                (x,y),                   #coordinate\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX,#font\n",
    "                                1,                       #font size\n",
    "                                255,                     #color\n",
    "                                2)                       #stroke weight\n",
    "                else:\n",
    "                    cv2.putText(img,          #window\n",
    "                                dictionary[str(personId)],#name\n",
    "                                (x,y),                   #coordinate\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX,#font\n",
    "                                1,                       #font size\n",
    "                                255,                     #color\n",
    "                                2)                       #stroke weight\n",
    "\n",
    "            else:\n",
    "                continue        \n",
    "            \n",
    "            cv2.imshow(\"image\",img)\n",
    "            \n",
    "            k = cv2.waitKey(10)\n",
    "            #press q to exit\n",
    "            if k & 0xFF == ord('q'):\n",
    "                break\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "   \n",
    "    \n",
    "# if __name__ == '__main__':\n",
    "#     test(\"image\",\"E:/project/small_face_dataset/Aaron_Eckhart/Aaron_Eckhart_20.jpg\")\n",
    "\n",
    "#     train_images, test_images, train_labels, test_labels = load(getItem_string(\"dataset\",\"test_dataset_path\"))   \n",
    "#     model = loadModel(getItem_string(\"dataset\",\"model_path\"))    \n",
    "#     evaluate(model, test_images, test_labels)\n",
    "\n",
    "#     train_images, test_images, train_labels, test_labels = load(getItem_string(\"dataset\",\"test_dataset_path\"))   \n",
    "#     model = build_model()\n",
    "#     model = train(model,10,train_images, train_labels)\n",
    "#     saveModel(model, getItem_string(\"dataset\",\"model_path\"))\n",
    "\n",
    "   \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
