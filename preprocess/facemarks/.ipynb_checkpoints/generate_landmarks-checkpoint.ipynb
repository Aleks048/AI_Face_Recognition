{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [
     59
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Aaron_Eckhart',\n",
       "  'Aaron_Guiel',\n",
       "  'Aaron_Peirsol',\n",
       "  'Aaron_Sorkin',\n",
       "  'Aaron_Tippin',\n",
       "  'Abba_Eban',\n",
       "  'Abbas_Kiarostami',\n",
       "  'Abdel_Aziz_Al-Hakim',\n",
       "  'Abdel_Madi_Shabneh',\n",
       "  'Abdel_Nasser_Assidi',\n",
       "  'Abdoulaye_Wade',\n",
       "  'Abdul_Majeed_Shobokshi',\n",
       "  'Abdul_Rahman',\n",
       "  'Abdulaziz_Kamilov',\n",
       "  'Abdullah',\n",
       "  'Abdullah_Ahmad_Badawi',\n",
       "  'Abdullah_Gul',\n",
       "  'Abdullah_Nasseef',\n",
       "  'Abdullatif_Sener',\n",
       "  'Abel_Aguilar',\n",
       "  'Abel_Pacheco',\n",
       "  'Abid_Hamid_Mahmud_Al-Tikriti',\n",
       "  'Abner_Martinez',\n",
       "  'Abraham_Foxman',\n",
       "  'Aby_Har-Even',\n",
       "  'Adam_Ant',\n",
       "  'Adam_Freier',\n",
       "  'Adam_Herbert',\n",
       "  'Adam_Kennedy',\n",
       "  'Adam_Mair',\n",
       "  'Adam_Rich',\n",
       "  'Adam_Sandler',\n",
       "  'Adam_Scott',\n",
       "  'Adel_Al-Jubeir',\n",
       "  'Adelina_Avila',\n",
       "  'Adisai_Bodharamik',\n",
       "  'Adolfo_Aguilar_Zinser',\n",
       "  'Adolfo_Rodriguez_Saa',\n",
       "  'Adoor_Gopalakarishnan'],\n",
       " 39,\n",
       " [],\n",
       " ['Aaron_Patterson', 'Aaron_Pena', 'Abdullah_al-Attiyah'])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import copy\n",
    "import csv\n",
    "from skimage import io\n",
    "import dlib\n",
    "import pandas as pd\n",
    "from ipynb.fs.full.config import getItem_string\n",
    "from ipynb.fs.full.config import getItem_int\n",
    "\n",
    "# create landmark detector\n",
    "facemark = cv2.face.createFacemarkLBF()\n",
    "# load lbf model\n",
    "facemark.loadModel(getItem_string(\"opencv\",\"facemark_model\"))   \n",
    "#create a classifier\n",
    "face_cascade = cv2.CascadeClassifier(getItem_string(\"opencv\",\"cascadeclassifier\")) \n",
    "\n",
    "#generate face data\n",
    "def generator(data):\n",
    "    name = input('my name:')\n",
    "    #if the directory exists, then delete\n",
    "    path = os.path.join(data,name)\n",
    "    if os.path.isdir(path):\n",
    "        shutil.rmtree(path) \n",
    "        \n",
    "    #create a directory\n",
    "    os.mkdir(path)\n",
    "    \n",
    "    #open camera  \n",
    "    camera = cv2.VideoCapture(0)\n",
    "    cv2.namedWindow('Camera')\n",
    "    #the index of face images\n",
    "    count = 1\n",
    "    size_of_image=getItem_int(\"dataset\",\"image_size\")\n",
    "    while(True):\n",
    "        #read a frame\n",
    "        ret,frame = camera.read()\n",
    "        #if successful\n",
    "        if ret:\n",
    "            #grayscale\n",
    "            grayscale_image = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "            #detect faces\n",
    "            faces = face_cascade.detectMultiScale(grayscale_image,1.3,5)            \n",
    "            for (x,y,w,h) in faces:\n",
    "                #draw rectangles \n",
    "                cv2.rectangle(frame,(x-20,y-20),(x+w+20,y+h+20),(255,0,0),2)\n",
    "                #adjust the size of image, same as images in database\n",
    "                f = cv2.resize(frame[y-20:y+h+20,x+20:x+w+20],(size_of_image,size_of_image))\n",
    "                #save faces\n",
    "                cv2.imwrite('%s/%s.jpg'%(path,str(count)),f)\n",
    "                count += 1                \n",
    "            cv2.imshow('Camera',frame)            \n",
    "            #press q to exit\n",
    "            if cv2.waitKey(100) & 0xff == ord('q') :\n",
    "                break\n",
    "    camera.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    \n",
    "#read images from database, get coordinate of landmarks\n",
    "def saveCSV(data):\n",
    "    #store all names\n",
    "    names = []\n",
    "    #no A face image in A directory\n",
    "    noFaceImg=[]\n",
    "    #unrecognized face \n",
    "    unrecognized=[]\n",
    "    #read directies in the path\n",
    "    path_list=os.listdir(data)\n",
    "    #sort directies\n",
    "    path_list.sort()  \n",
    "    #read all face images from directory\n",
    "    for subDirname in path_list:\n",
    "        #each subDirname represents a person\n",
    "        subjectPath = os.path.join(data,subDirname)\n",
    "        if os.path.isdir(subjectPath):    \n",
    "            #store face images of a person\n",
    "            images = []\n",
    "            #for each face image of a person\n",
    "            for fileName in os.listdir(subjectPath):\n",
    "                imgPath = os.path.join(subjectPath,fileName)\n",
    "                #convert into grascale\n",
    "                img = cv2.imread(imgPath,cv2.IMREAD_GRAYSCALE)\n",
    "                images.append(img)          \n",
    "            #for each person, there could be many face images,therefore many facemarks, store them in a list\n",
    "            landmark=[]\n",
    "            #if there exist a image\n",
    "            if len(images)>0:  \n",
    "                #for each person \n",
    "                for face_image in images:\n",
    "                    #detect faces\n",
    "                    faces = face_cascade.detectMultiScale(face_image,1.3,5)  \n",
    "                    for (x,y,w,h) in faces:\n",
    "                        #create landmarks for each detected face, we know each image only contains one face\n",
    "                        #landmarks is a 4D array  len(landmarks) = number of faces in a image \n",
    "                        ok, landmarks = facemark.fit(face_image, faces)\n",
    "                        #if there are more than one face images from one person, add all facemarks of him into a list \n",
    "                        for i in landmarks[0][0]:#landmarks[0][0] = [[x,y] [x,y] [x,y] [x,y]], innner array are coordinates\n",
    "                            landmark.append(i) # i is a coordinate \n",
    "                #save landmarks into csv\n",
    "                f=open(getItem_string(\"opencv\",\"landmarkcsv\"),'a')\n",
    "                writer = csv.writer(f,lineterminator='\\n')\n",
    "                if len(landmark)>0:\n",
    "                    #add that detected person in a names list \n",
    "                    names.append(subDirname)\n",
    "                    #if landmarks is detected successfully, we just choose first one (there could be more than one landmarks in list)\n",
    "                    for i in range(68):\n",
    "                        writer.writerow(landmark[i])\n",
    "                else :\n",
    "                   unrecognized.append(subDirname)\n",
    "                f.close()\n",
    "            else:#no face images\n",
    "                noFaceImg.append(subDirname) \n",
    "            with open(getItem_string(\"opencv\",\"outputtxt\"),\"w\") as f:\n",
    "                for i in names:\n",
    "                    f.write(i)\n",
    "                    f.write('\\n')\n",
    "    return names,len(names),noFaceImg,unrecognized\n",
    "\n",
    "def readCSV():\n",
    "    landmarks=[]\n",
    "    #return a DataFrame [x*68 rows x 2 columns]\n",
    "    matrix = pd.read_csv(getItem_string(\"opencv\",\"landmarkcsv\"),header=None)\n",
    "    # convert into array\n",
    "    coordinates = matrix.to_numpy()\n",
    "    #convert into 3D array [[[x,y][x,y]] [[x,y][x,y]] [[x,y][x,y]]]     [all facemaks  [a person[coordinate]..[coordinate]]]\n",
    "    shape=(int(len(coordinates)/68),68,2) #(x,68,2)\n",
    "    landmarks=coordinates.reshape(shape)\n",
    "#     print(coordinates[0])\n",
    "    return landmarks\n",
    "\n",
    "def getline(thefilepath, desired_line_number):\n",
    "    if desired_line_number < 1: \n",
    "        return ''\n",
    "    for current, line in enumerate(open(thefilepath, 'r')):\n",
    "        if current == desired_line_number - 1 : \n",
    "            return line[:-1]\n",
    "    return ''\n",
    "\n",
    "data = getItem_string(\"dataset\",\"dataset_path\")\n",
    "# generator(data)\n",
    "saveCSV(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
